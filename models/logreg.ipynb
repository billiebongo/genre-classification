{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Packages needed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to /home/sloth/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to /home/sloth/nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import seaborn as sns\n",
    "import re\n",
    "\n",
    "import pickle \n",
    "import time\n",
    "\n",
    "from nltk.tokenize import TweetTokenizer # doesn't split at apostrophes\n",
    "from nltk import Text\n",
    "from nltk.tokenize import regexp_tokenize\n",
    "from nltk.tokenize import word_tokenize \n",
    "import nltk\n",
    "\n",
    "\n",
    "from nltk.tokenize import sent_tokenize\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from nltk.stem import PorterStemmer\n",
    "\n",
    "\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.linear_model import LogisticRegression \n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.multiclass import OneVsRestClassifier\n",
    "\n",
    "\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import metrics\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.pipeline import make_pipeline\n",
    "\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer, CountVectorizer, TfidfTransformer\n",
    "\n",
    "from clean_data import clean_description as clean_des\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Loading Book data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "genre\n",
      "1                       1\n",
      "1999                    1\n",
      "2005                    1\n",
      "Science-fiction         1\n",
      "Self-help               1\n",
      "adventure             684\n",
      "art                   599\n",
      "biography            2612\n",
      "biology                40\n",
      "business             1151\n",
      "chick-lit             721\n",
      "children             3663\n",
      "comics                369\n",
      "computer-science       80\n",
      "cookbook              514\n",
      "drama                 515\n",
      "economics             202\n",
      "entrepreneurship       15\n",
      "fantasy              6929\n",
      "fiction              6857\n",
      "finance               216\n",
      "gr                     42\n",
      "health                605\n",
      "historical           1427\n",
      "history              3178\n",
      "horror               1302\n",
      "humour                423\n",
      "math                  199\n",
      "mystery              4843\n",
      "nil                 57204\n",
      "non-fiction          4996\n",
      "philosophy            553\n",
      "physics                21\n",
      "politics              743\n",
      "psychology            769\n",
      "religion             1179\n",
      "romance              4092\n",
      "science              1352\n",
      "science-fiction      1993\n",
      "scifi                  36\n",
      "scifi3                  1\n",
      "self-help            1036\n",
      "social-science         30\n",
      "thriller             1149\n",
      "travel                687\n",
      "young-adult          4473\n",
      "Name: id, dtype: int64\n",
      "dimension of data (117505, 7)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>id</th>\n",
       "      <th>book_title</th>\n",
       "      <th>authors</th>\n",
       "      <th>pub_year</th>\n",
       "      <th>genre</th>\n",
       "      <th>description</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>89</td>\n",
       "      <td>Factfulness: Ten Reasons We're Wrong About the...</td>\n",
       "      <td>[Hans Rosling, Anna Rosling Rönnlund, Ola Rosl...</td>\n",
       "      <td>2018</td>\n",
       "      <td>non-fiction</td>\n",
       "      <td>Factfulness: The stress-reducing habit of only...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>90</td>\n",
       "      <td>Magic, Madness, and Mischief</td>\n",
       "      <td>[Kelly McCullough]</td>\n",
       "      <td>2018</td>\n",
       "      <td>fantasy</td>\n",
       "      <td>\"A 12-year-old boy uses his new magical powers...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>91</td>\n",
       "      <td>Spirits, Spells, and Snark</td>\n",
       "      <td>[Kelly McCullough]</td>\n",
       "      <td>2019</td>\n",
       "      <td>fantasy</td>\n",
       "      <td>Kalvan Monroe is worried. Every story he's eve...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>92</td>\n",
       "      <td>First Kisses and Other Misfortunes (Grimbaud, ...</td>\n",
       "      <td>[Kimberly Karalius]</td>\n",
       "      <td>2016</td>\n",
       "      <td>young-adult</td>\n",
       "      <td>In Kimberly Karalius's First Kisses and Other ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>93</td>\n",
       "      <td>Law School Confidential: A Complete Guide to t...</td>\n",
       "      <td>[Robert H.    Miller]</td>\n",
       "      <td>2015</td>\n",
       "      <td>non-fiction</td>\n",
       "      <td>I WISH I KNEW THEN WHAT I KNOW NOW!\\n\\nDon't g...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0  id                                         book_title  \\\n",
       "0           0  89  Factfulness: Ten Reasons We're Wrong About the...   \n",
       "1           1  90                       Magic, Madness, and Mischief   \n",
       "2           2  91                         Spirits, Spells, and Snark   \n",
       "3           3  92  First Kisses and Other Misfortunes (Grimbaud, ...   \n",
       "4           4  93  Law School Confidential: A Complete Guide to t...   \n",
       "\n",
       "                                             authors pub_year        genre  \\\n",
       "0  [Hans Rosling, Anna Rosling Rönnlund, Ola Rosl...     2018  non-fiction   \n",
       "1                                 [Kelly McCullough]     2018      fantasy   \n",
       "2                                 [Kelly McCullough]     2019      fantasy   \n",
       "3                                [Kimberly Karalius]     2016  young-adult   \n",
       "4                              [Robert H.    Miller]     2015  non-fiction   \n",
       "\n",
       "                                         description  \n",
       "0  Factfulness: The stress-reducing habit of only...  \n",
       "1  \"A 12-year-old boy uses his new magical powers...  \n",
       "2  Kalvan Monroe is worried. Every story he's eve...  \n",
       "3  In Kimberly Karalius's First Kisses and Other ...  \n",
       "4  I WISH I KNEW THEN WHAT I KNOW NOW!\\n\\nDon't g...  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Data description\n",
    "df = pd.read_csv('../data/book_data.csv')\n",
    "df.drop([\"src\", \"cover\"], inplace=True, axis=1) # Image data will not be used\n",
    "total = df.isnull().sum().sort_values(ascending=False)\n",
    "\n",
    "print(df.groupby(['genre']).count()[\"id\"])\n",
    "print(\"dimension of data {}\".format(df.shape))\n",
    "df.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fixing dirty data\n",
      "Removing rows of corrupted data from df\n",
      "genre\n",
      "adventure             684\n",
      "art                   599\n",
      "biography            2612\n",
      "biology                40\n",
      "business             1151\n",
      "chick-lit             721\n",
      "children             3663\n",
      "comics                369\n",
      "computer-science       80\n",
      "cookbook              514\n",
      "drama                 515\n",
      "economics             202\n",
      "entrepreneurship       15\n",
      "fantasy              6929\n",
      "fiction              6857\n",
      "finance               216\n",
      "gr                     42\n",
      "health                605\n",
      "historical           1427\n",
      "history              3178\n",
      "horror               1302\n",
      "humour                423\n",
      "math                  199\n",
      "mystery              4843\n",
      "nil                 57204\n",
      "non-fiction          4996\n",
      "philosophy            553\n",
      "physics                21\n",
      "politics              743\n",
      "psychology            769\n",
      "religion             1179\n",
      "romance              4092\n",
      "science              1352\n",
      "science-fiction      2031\n",
      "self-help            1037\n",
      "social-science         30\n",
      "thriller             1149\n",
      "travel                687\n",
      "young-adult          4473\n",
      "Name: id, dtype: int64\n",
      "Genres available: \n",
      "['non-fiction' 'fantasy' 'young-adult' 'mystery' 'romance' 'fiction'\n",
      " 'horror' 'children' 'thriller' 'nil' 'business' 'economics' 'cookbook'\n",
      " 'art' 'biography' 'travel' 'science' 'politics' 'history' 'adventure'\n",
      " 'science-fiction' 'chick-lit' 'self-help' 'historical' 'math' 'humour'\n",
      " 'philosophy' 'psychology' 'drama' 'religion' 'health' 'gr' 'comics'\n",
      " 'physics' 'finance' 'computer-science' 'biology' 'social-science'\n",
      " 'entrepreneurship']\n"
     ]
    }
   ],
   "source": [
    "print(\"Fixing dirty data\")\n",
    "# strange genres/ dirty data\n",
    "df.genre[df.genre==\"scifi3\"] = \"science-fiction\"\n",
    "df.genre[df.genre==\"Science-fiction\"] = \"science-fiction\"\n",
    "df.genre[df.genre==\"scifi\"] = \"science-fiction\"\n",
    "df.genre[df.genre==\"Self-help\"] = \"self-help\"\n",
    "\n",
    "print(\"Removing rows of corrupted data from df\")\n",
    "df = df[df.genre != \"1\"]\n",
    "df = df[df.genre != \"1999\"]\n",
    "df = df[df.genre != \"2005\"]\n",
    "print(df.groupby(['genre']).count()[\"id\"])\n",
    "GENRE_LIST = df[\"genre\"].unique()\n",
    "print(\"Genres available: \")\n",
    "print(GENRE_LIST)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "remove books with \"nil\" description\n",
      "117502\n",
      "Number of books with 0/1 word\n",
      "Unnamed: 0         5\n",
      "id                 5\n",
      "book_title         5\n",
      "authors            5\n",
      "pub_year           5\n",
      "genre              5\n",
      "description        5\n",
      "desc_word_count    5\n",
      "dtype: int64\n",
      "Unnamed: 0         21994\n",
      "id                 21994\n",
      "book_title         21994\n",
      "authors            21994\n",
      "pub_year           21994\n",
      "genre              21994\n",
      "description           74\n",
      "desc_word_count    21994\n",
      "dtype: int64\n",
      "Index(['Unnamed: 0', 'id', 'book_title', 'authors', 'pub_year', 'genre',\n",
      "       'description', 'desc_word_count'],\n",
      "      dtype='object')\n",
      "Number of books left after books with no descriptions\n",
      "95503\n"
     ]
    }
   ],
   "source": [
    "# Cleaning more data\n",
    "print(\"remove books with \\\"nil\\\" description\")\n",
    "\n",
    "#27 titles with \"nil\" description\n",
    "\n",
    "df['desc_word_count']=df[\"description\"].apply(lambda x: len(str(x).split()))\n",
    "print(df[\"book_title\"].count())\n",
    "print(\"Number of books with 0/1 word\")\n",
    "print(df[df.desc_word_count == 0].count())\n",
    "print(df[df.desc_word_count == 1].count())\n",
    "\n",
    "df=df[df.desc_word_count != 1]\n",
    "df=df[df.desc_word_count != 0]\n",
    "\n",
    "print(df.columns)\n",
    "print(\"Number of books left after books with no descriptions\")\n",
    "print(df[\"book_title\"].count())\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "genre\n",
      "adventure             631\n",
      "art                   522\n",
      "biography            2276\n",
      "biology                33\n",
      "business              996\n",
      "chick-lit             666\n",
      "children             3230\n",
      "comics                337\n",
      "computer-science       56\n",
      "cookbook              415\n",
      "drama                 473\n",
      "economics             167\n",
      "entrepreneurship        8\n",
      "fantasy              6527\n",
      "fiction              6067\n",
      "finance               182\n",
      "health                529\n",
      "historical           1344\n",
      "history              2824\n",
      "horror               1207\n",
      "humour                379\n",
      "math                  157\n",
      "mystery              4544\n",
      "nil                 41598\n",
      "non-fiction          4009\n",
      "philosophy            470\n",
      "physics                13\n",
      "politics              653\n",
      "psychology            663\n",
      "religion             1005\n",
      "romance              3670\n",
      "science              1114\n",
      "science-fiction      1845\n",
      "self-help             915\n",
      "social-science         22\n",
      "thriller             1078\n",
      "travel                609\n",
      "young-adult          4269\n",
      "Name: id, dtype: int64\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(95503, 8)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Cleaned data finally\n",
    "print(df.groupby(['genre']).count()[\"id\"])\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(53905, 8)\n",
      "(41598, 8)\n",
      "   Unnamed: 0  id                                         book_title  \\\n",
      "0           0  89  Factfulness: Ten Reasons We're Wrong About the...   \n",
      "1           1  90                       Magic, Madness, and Mischief   \n",
      "2           2  91                         Spirits, Spells, and Snark   \n",
      "3           3  92  First Kisses and Other Misfortunes (Grimbaud, ...   \n",
      "4           4  93  Law School Confidential: A Complete Guide to t...   \n",
      "\n",
      "                                             authors pub_year        genre  \\\n",
      "0  [Hans Rosling, Anna Rosling Rönnlund, Ola Rosl...     2018  non-fiction   \n",
      "1                                 [Kelly McCullough]     2018      fantasy   \n",
      "2                                 [Kelly McCullough]     2019      fantasy   \n",
      "3                                [Kimberly Karalius]     2016  young-adult   \n",
      "4                              [Robert H.    Miller]     2015  non-fiction   \n",
      "\n",
      "                                         description  desc_word_count  \n",
      "0  Factfulness: The stress-reducing habit of only...              151  \n",
      "1  \"A 12-year-old boy uses his new magical powers...               28  \n",
      "2  Kalvan Monroe is worried. Every story he's eve...              126  \n",
      "3  In Kimberly Karalius's First Kisses and Other ...              162  \n",
      "4  I WISH I KNEW THEN WHAT I KNOW NOW!\\n\\nDon't g...              155  \n"
     ]
    }
   ],
   "source": [
    "# use books with \"nil\" as genres as test dat\n",
    "train_df = df[df.genre != \"nil\"]\n",
    "test_df = df[df.genre == \"nil\"]\n",
    "\n",
    "print(train_df.shape)\n",
    "print(test_df.shape)\n",
    "print(train_df.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Clean text for building models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from clean_data import clean_description as clean_des\n",
    "\n",
    "train_df['description']=(train_df['description'].apply(clean_des))\n",
    "test_df['description']=(test_df['description'].apply(clean_des))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TF-IDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(95503, 8)\n"
     ]
    }
   ],
   "source": [
    "# TFIDF matrices\n",
    "tf = TfidfVectorizer(smooth_idf=False, min_df=2, max_df=0.8,sublinear_tf=False, norm=None, analyzer='word')\n",
    "\n",
    "df['description']=(df['description'].apply(clean_des))\n",
    "\n",
    "print(df.shape)\n",
    "df = df[df.description!=\"\"]\n",
    "df = df[df.description!=np.nan]\n",
    "\n",
    "txt_fitted=tf.fit(df['description'].values.astype('U'))\n",
    "txt_transformed = txt_fitted.transform(df['description'].values.astype('U'))\n",
    "idf = tf.idf_\n",
    "\n",
    "#print(dict(zip(txt_fitted.get_feature_names(), idf)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Features with lowest idf:\n",
      "['book' 'one' 'life' 'new' 'time' 'world' 'find' 'stori' 'make' 'year']\n"
     ]
    }
   ],
   "source": [
    "feature_names = np.array(tf.get_feature_names())\n",
    "sorted_by_idf = np.argsort(tf.idf_)\n",
    "print(\"Features with lowest idf:\\n{}\".format(\n",
    "       feature_names[sorted_by_idf[:10]]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sort_coo(coo_matrix):\n",
    "    tuples = zip(coo_matrix.col, coo_matrix.data)\n",
    "    return sorted(tuples, key=lambda x: (x[1], x[0]), reverse=False)\n",
    "\n",
    "def extract_topn_from_vector(feature_names, sorted_items, topn=10):\n",
    "    \"\"\"get the feature names and tf-idf score of top n items\"\"\"\n",
    "    \n",
    "    #use only topn items from vector\n",
    "    sorted_items = sorted_items[:topn]\n",
    " \n",
    "    score_vals = []\n",
    "    feature_vals = []\n",
    "    \n",
    "    # word index and corresponding tf-idf score\n",
    "    for idx, score in sorted_items:\n",
    "        \n",
    "        #keep track of feature name and its corresponding score\n",
    "        score_vals.append(round(score, 3))\n",
    "        feature_vals.append(feature_names[idx])\n",
    " \n",
    "    #create a tuples of feature,score\n",
    "    #results = zip(feature_vals,score_vals)\n",
    "    results= {}\n",
    "    for idx in range(len(feature_vals)):\n",
    "        results[feature_vals[idx]]=score_vals[idx]\n",
    "    \n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#instead of dumping tfidf into the logistic, dump count into tfidf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Count Vectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "cv = CountVectorizer(max_df=0.85, analyzer=\"word\")\n",
    "cv.fit(train_df[\"description\"])\n",
    "xtrain_count_vector = cv.transform(train_df[\"description\"])\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0    fact habit carri opinion strong support fact a...\n",
      "1    boy use new magic power help snarki fire hare ...\n",
      "2    kalvan monro worri everi stori ever read told ...\n",
      "3    kimber karalius first kiss misfortun two boy d...\n",
      "4    wish knew know get end law school career mutte...\n",
      "Name: description, dtype: object\n"
     ]
    }
   ],
   "source": [
    "#print(cv.get_feature_names())\n",
    "print(train_df[\"description\"].head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TfidfTransformer(norm='l2', smooth_idf=True, sublinear_tf=False, use_idf=True)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tfidf_transformer = TfidfTransformer(smooth_idf=True,use_idf=True)\n",
    "tfidf_transformer.fit(xtrain_count_vector)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "doc=train_df[\"description\"].tolist()[0]\n",
    "#print(doc)\n",
    "\n",
    "feature_names=cv.get_feature_names()\n",
    "tf_idf_vector=tfidf_transformer.transform(cv.transform([doc]))\n",
    " \n",
    "tf_idf_vector=tfidf_transformer.transform(cv.transform([doc]))\n",
    "sorted_items=sort_coo(tf_idf_vector.tocoo())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=====Doc=====\n",
      "fact habit carri opinion strong support fact ask simpl question global percentag world popul live poverti world popul increas mani girl finish systemat get answer wrong wrong chimpanze choos answer random consist outguess teacher journalist nobel laureat invest banker fact professor intern health global ted phenomenon han rosl togeth two collabor anna ola offer radic new explan happen reveal ten instinct distort tendenc divid world two camp usual version us way consum media fear rule perceiv progress believ thing get wors problem know\n",
      "\n",
      "===Keywords===\n",
      "new 0.04\n",
      "live 0.049\n",
      "way 0.053\n",
      "know 0.056\n",
      "thing 0.062\n",
      "mani 0.063\n",
      "girl 0.063\n",
      "us 0.067\n",
      "togeth 0.067\n",
      "offer 0.067\n"
     ]
    }
   ],
   "source": [
    "#extract only the top n; n here is 10\n",
    "keywords=extract_topn_from_vector(feature_names,sorted_items,10)\n",
    " \n",
    "# now print the results\n",
    "print(\"\\n=====Doc=====\")\n",
    "print(doc)\n",
    "print(\"\\n===Keywords===\")\n",
    "for k in keywords:\n",
    "    print(k,keywords[k])\n",
    " \n",
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Cross Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(train_df[\"description\"], train_df[\"genre\"], test_size= 0.1, random_state=13)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Instantiate the vectorizer\n",
    "word_vectorizer = TfidfVectorizer(min_df=2, max_df=0.8,\n",
    "    stop_words='english',\n",
    "    sublinear_tf=True,\n",
    "    strip_accents='unicode',\n",
    "    analyzer='word',\n",
    "    token_pattern=r'\\w{2,}',  #vectorize 2-character words or more\n",
    "    ngram_range=(1, 1),\n",
    "                                  \n",
    "    max_features=300000)\n",
    "# fit and transform on it the training features\n",
    "\n",
    "word_vectorizer.fit(X_train)\n",
    "X_train_word_features = word_vectorizer.transform(X_train)\n",
    "\n",
    "#transform the test features to sparse matrix\n",
    "test_features = word_vectorizer.transform(X_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create regularization penalty space\n",
    "penalty = ['l1', 'l2']\n",
    "\n",
    "# Create regularization hyperparameter space\n",
    "C = np.logspace(0, 2, 4, 10)\n",
    "\n",
    "# Create hyperparameter options\n",
    "hyperparameters = dict(C=C, penalty=penalty)\n",
    "\n",
    "logistic = LogisticRegression()\n",
    "classifier = GridSearchCV(logistic, hyperparameters, cv=5, verbose=0)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Building Model and adjusting parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model is done fitting\n",
      "CV Accuracy score is 0.6107322646758823\n",
      "Best Penalty: l2\n",
      "Best C: 21.544346900318832\n"
     ]
    }
   ],
   "source": [
    "best_model=classifier.fit(X_train_word_features, y_train)\n",
    "print(\"Model is done fitting\")\n",
    "y_pred = classifier.predict(test_features)\n",
    "y_pred_prob = classifier.predict_proba(test_features)[:, 1]\n",
    "cv_score = np.mean(cross_val_score(classifier, X_train_word_features, y_train,\n",
    "                                   cv=5,scoring='accuracy'))\n",
    "print('CV Accuracy score is {}'.format( cv_score))\n",
    "# View best hyperparameters\n",
    "print('Best Penalty:', best_model.best_estimator_.get_params()['penalty'])\n",
    "print('Best C:', best_model.best_estimator_.get_params()['C'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(5391,)\n",
      "(5391,)\n",
      "<class 'numpy.ndarray'>\n",
      "(5391,)\n",
      "40\n",
      "thriller mystery\n",
      "22\n",
      "41\n",
      "biography non-fiction\n",
      "23\n",
      "42\n",
      "self-help self-help\n",
      "32\n",
      "43\n",
      "fiction fiction\n",
      "14\n",
      "44\n",
      "self-help religion\n",
      "28\n",
      "45\n",
      "non-fiction non-fiction\n",
      "23\n",
      "46\n",
      "romance romance\n",
      "29\n",
      "47\n",
      "biography fiction\n",
      "14\n",
      "48\n",
      "humour non-fiction\n",
      "23\n",
      "49\n",
      "mystery mystery\n",
      "22\n",
      "50\n",
      "mystery fiction\n",
      "14\n",
      "51\n",
      "fantasy fantasy\n",
      "13\n",
      "52\n",
      "business non-fiction\n",
      "23\n",
      "53\n",
      "fantasy fantasy\n",
      "13\n",
      "54\n",
      "young-adult young-adult\n",
      "36\n",
      "55\n",
      "history history\n",
      "18\n",
      "56\n",
      "fiction fiction\n",
      "14\n",
      "57\n",
      "business history\n",
      "18\n",
      "58\n",
      "fantasy fantasy\n",
      "13\n",
      "59\n",
      "thriller thriller\n",
      "34\n",
      "60\n",
      "biography biography\n",
      "2\n",
      "61\n",
      "psychology psychology\n",
      "27\n",
      "62\n",
      "children children\n",
      "6\n",
      "63\n",
      "science-fiction science-fiction\n",
      "31\n",
      "64\n",
      "history history\n",
      "18\n",
      "65\n",
      "thriller mystery\n",
      "22\n",
      "66\n",
      "mystery mystery\n",
      "22\n",
      "67\n",
      "children children\n",
      "6\n",
      "68\n",
      "children children\n",
      "6\n",
      "69\n",
      "non-fiction non-fiction\n",
      "23\n",
      "70\n",
      "fantasy fantasy\n",
      "13\n",
      "71\n",
      "non-fiction non-fiction\n",
      "23\n",
      "72\n",
      "romance romance\n",
      "29\n",
      "73\n",
      "fantasy fantasy\n",
      "13\n",
      "74\n",
      "biography non-fiction\n",
      "23\n",
      "75\n",
      "business business\n",
      "4\n",
      "76\n",
      "children fiction\n",
      "14\n",
      "77\n",
      "romance chick-lit\n",
      "5\n",
      "78\n",
      "biography biography\n",
      "2\n",
      "79\n",
      "history history\n",
      "18\n",
      "80\n",
      "historical romance\n",
      "29\n",
      "81\n",
      "biography biography\n",
      "2\n",
      "82\n",
      "humour science\n",
      "30\n",
      "83\n",
      "young-adult young-adult\n",
      "36\n",
      "84\n",
      "science science\n",
      "30\n",
      "85\n",
      "young-adult young-adult\n",
      "36\n",
      "86\n",
      "religion religion\n",
      "28\n",
      "87\n",
      "historical fiction\n",
      "14\n",
      "88\n",
      "children children\n",
      "6\n",
      "89\n",
      "historical mystery\n",
      "22\n",
      "90\n",
      "historical chick-lit\n",
      "5\n",
      "91\n",
      "young-adult young-adult\n",
      "36\n",
      "92\n",
      "history history\n",
      "18\n",
      "93\n",
      "fiction science-fiction\n",
      "31\n",
      "94\n",
      "children fantasy\n",
      "13\n",
      "95\n",
      "science science\n",
      "30\n",
      "96\n",
      "fiction fiction\n",
      "14\n",
      "97\n",
      "young-adult fantasy\n",
      "13\n",
      "98\n",
      "cookbook cookbook\n",
      "9\n",
      "99\n",
      "fiction fiction\n",
      "14\n"
     ]
    }
   ],
   "source": [
    "print(y_test.shape)\n",
    "print(y_pred.shape)\n",
    "test_features = word_vectorizer.transform(X_test)\n",
    "y_pred_prob = classifier.predict_proba(test_features).argmax(axis=-1)\n",
    "print(type(y_pred_prob))\n",
    "print(y_pred_prob.shape)\n",
    "\n",
    "# This is just for getting a sample of classification results of model on test data\n",
    "for i in range(40,100):\n",
    "    print(i)\n",
    "    print(y_test.iloc[i],y_pred[i] )\n",
    "    print(y_pred_prob[i])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_best_score(grid):\n",
    "    \n",
    "    best_score = np.sqrt(-grid.best_score_)\n",
    "    print(best_score)    \n",
    "    print(grid.best_params_)\n",
    "    print(grid.best_estimator_)\n",
    "    \n",
    "    return best_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'numpy.ndarray'>\n"
     ]
    }
   ],
   "source": [
    "#print(\"best\")\n",
    "#print('Best pen:', best_model.best_estimator_.get_params())\n",
    "#pd.options.display.max_colwidth = 1000\n",
    "\n",
    "##print(len(X_test))\n",
    "#print(type(y_test))\n",
    "print(type(y_pred))\n",
    "\n",
    "#for i in range(3,100):\n",
    "#    print(X_test.iloc[i])\n",
    "#    print(\"ground truth: {}\".format(str(y_test.iloc[i])))\n",
    "#    print(\"predict: {}\".format(str(y_pred[i])))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "ename": "IndexError",
     "evalue": "single positional indexer is out-of-bounds",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-25-3df69fca3f19>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0msample1\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtest_df\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m50\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;36m90\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mbook_idx\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m44\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msample1\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0miloc\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mbook_idx\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"book_title\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0msample1\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0miloc\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mbook_idx\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"description\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/pandas/core/indexing.py\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   1476\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1477\u001b[0m             \u001b[0mmaybe_callable\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcom\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_apply_if_callable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1478\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_getitem_axis\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmaybe_callable\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1479\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1480\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_is_scalar_access\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/pandas/core/indexing.py\u001b[0m in \u001b[0;36m_getitem_axis\u001b[0;34m(self, key, axis)\u001b[0m\n\u001b[1;32m   2100\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2101\u001b[0m             \u001b[0;31m# validate the location\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2102\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_validate_integer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2103\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2104\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_loc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/pandas/core/indexing.py\u001b[0m in \u001b[0;36m_validate_integer\u001b[0;34m(self, key, axis)\u001b[0m\n\u001b[1;32m   2007\u001b[0m         \u001b[0ml\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0max\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2008\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mkey\u001b[0m \u001b[0;34m>=\u001b[0m \u001b[0ml\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mkey\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0ml\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2009\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mIndexError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"single positional indexer is out-of-bounds\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2010\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2011\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_getitem_tuple\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtup\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mIndexError\u001b[0m: single positional indexer is out-of-bounds"
     ]
    }
   ],
   "source": [
    "sample1=test_df[50:90]\n",
    "book_idx=44\n",
    "print(sample1.iloc[book_idx][\"book_title\"])\n",
    "sample1.iloc[book_idx][\"description\"]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_top_5_predictions(predictions):\n",
    "    genre_list = train_df[\"genre\"]\n",
    "    print(genre_list.shape)\n",
    "    return\n",
    "\n",
    "get_top_5_predictions(\"bla\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_model\n",
    "sample1_word_features = word_vectorizer.transform(sample1)\n",
    "\n",
    "y_pred = classifier.predict(test_features)\n",
    "y_pred = classifier.predict(test_features)\n",
    "y_pred_prob = classifier.predict_proba(test_features)\n",
    "print(y_pred[book_idx])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_classes = y_pred_prob.argmax(axis=-1)\n",
    "y_classes\n",
    "print(y_classes[book_idx]\n",
    "     )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python3.6Test",
   "language": "python",
   "name": "python3.6test"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
